### 目录
[toc]

### 重点

### 数据结构(TODO)

#### 树

##### 平衡二叉树

1. 非叶子节点最多拥有两个子节点
2. 非叶子节值大于左边子节点、小于右边子节点
3. 树的左右两边的层级数相差不会大于1
4. 没有值相等重复的节点;

##### B 树

![image-20200802152638792](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802152638792.png)

![image-20200802152704652](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802152704652.png)![image-20200802152715752](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802152715752.png)

![image-20200802152724602](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802152724602.png)

##### B+ 树



![image-20200802152751752](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802152751752.png)

![image-20200802152959465](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802152959465.png)

##### AVL 树

![image-20200802153841305](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802153841305.png)

##### 2-3 树



##### 红黑树

![image-20200802153952682](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802153952682.png)

#### 哈希表

基本概念: 通过数学方法计算散列值

![image-20200802155010040](C:\Users\commo\AppData\Roaming\Typora\typora-user-images\image-20200802155010040.png)

##### 开放定址法

1. 线性探测法
2. 平方探测法
3. 双散列函数探测法

##### 再哈希法

##### 链地址法

##### 建立公共溢出区

### 算法

#### 排序

##### 冒泡

```python
# 冒泡把最小(大)的排序
def bubble_sort(nums):
    for i in range(len(nums)):
        for j in range(len(nums) - i - 1):
            if nums[j] > nums[j + 1]:
                nums[j], nums[j + 1] = nums[j + 1], nums[j]
    return nums
```

##### 选择

```python
# 选择最小(大)的往前排
def section_sort(nums):
    for i in range(len(nums)-1):
        for j in range(i+1, len(nums)):
            if nums[i] > nums[j]:
                nums[i], nums[j] = nums[j], nums[i]
    return nums
```

##### 插入排序

```python
# 左边都是排好序的, 将右边的插入排好序的列表
def insert_sort(nums):
    for i in range(len(nums)):
        j = i
        while j > 0 and nums[j] < nums[j-1]:
            nums[j], nums[j-1] = nums[j-1], nums[j]
            j -= 1
    return nums
```



### 计算机网络

#### 网络结构

##### 计算机网络有哪些结构

1. OSI 七层模型
2. TCP/IP 模型
  3. 五层协议模型

##### 各层有什么用

1. 应用层
   通过**应用进程间的交互**来完成特定网络应用，常见的协议有**域名系统DNS**，万维网应用的**HTTP协议**，支持**电子邮件的SMTP协议**。把应用层交互的数据单元称为**报文**
2. 运输层
   为两台主机进程之间的通信提供**通用的数据传输服务。**主要包含两种协议：
   - **传输控制协议 TCP**（Transmisson Control Protocol）。提供**面向连接**的，**可靠的**数据传输服务。
   - **用户数据协议 UDP**（User Datagram Protocol）。提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）
3. 网络层
   使用IP协议。网络层有两个任务：
   - 把运输层产生的报文段或用户数据报**封装成分组和包进行传送**。在 TCP/IP 体系结构中，由于网络层使用 **IP 协议**，因此分组也叫 **IP 数据报** ，简称 **数据报**。注意：不要把运输层的用户数据报UDP和网络层的IP数据报弄混。
   - 选择合适的路由，找到目的主机
4. 数据链路层
   两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装程帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）
5. 物理层
   物理层的任务就是**透明地传输比特流**，换句话说实际电路传送后比特流没有发生变化

#### TCP/IP 协议

##### TCP/IP 的结构

​	![TCP/IP_sructure](https://uk-1259555870.cos.eu-frankfurt.myqcloud.com/20200216134831.png)

##### TCP 和 UDP 的区别

总结：

- TCP：面向连接，面向字节流，可靠，传输慢，有流量控制阻塞控制
- UDP：广播形式不需要连接，面向报文，不可靠，传输快，无流量控制阻塞控制

头部数据结构:

- TCP:  
- UDP:

解释一下报文和字节流的区别：

- 字节流：**发送次数和接收次数可以不相同**，比如向水池倒了20盆水，可以开水龙头一次性全放出。
- 报文：**发送次数和接收次数必须相同**

应用场景：

- TCP：邮件，远程登录，文件传输等对准确性要求较高的地方
- UDP：及时通信，比如QQ，网络电话等

##### 三次握手和四次挥手(TODO)

##### TCP 如何保证可靠

1. 采用三次握手四次挥手保证建立的**传输信道是可靠的**
2. 采用了**ARQ自动重传请求**协议**数据传输的可靠性**
3. 采用**滑动窗口**协议进行流量控制
4. 使用**慢开始**、**拥塞避免**、**快重传**和**快恢复**来进行**拥塞控制**

##### TCP 如何进行流量控制

TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）

##### TCP 何如进行拥塞避免

网络拥塞是指在**分组交换网络中传送分组的数目太多**时，由于存储转发节点的资源有限而造成网络传输性能下降的情况。

常见的拥塞控制有：

- 慢开始
- 拥塞避免
- 快重传
- 快恢复

发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。当cwndssthresh时，改用拥塞避免算法。

**慢开始：**不要一开始就发送大量的数据，由小到大逐渐增加拥塞窗口的大小。

**拥塞避免：**拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1而不是加倍。这样拥塞窗口按线性规律缓慢增长。

**快重传：**我们可以剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方在**收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认。**快重传规定：发送方只要**一连收到三个**重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

![img](https://uk-1259555870.cos.eu-frankfurt.myqcloud.com/20200214125708.png)

**快恢复：**主要是配合快重传。当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞），但**接下来并不执行慢开始算法**，因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三个重复确认说明网络状况还可以。

![img](https://uk-1259555870.cos.eu-frankfurt.myqcloud.com/20200214130136.png)

#### DNS和ARP

##### DNS解析过程

将域名解析为IP地址,优先加载本地**Host**文件和本地**DNS**解析器是否有映射,没有则向上一级请求:

- 迭代
  代理服务器返回下一级DNS服务器地址
- 递归
  代理服务器帮忙请求

##### 什么是MAC地址

设备的硬件地址, 链路层的MAC帧传输使用MAC地址

##### ARP协议的工作机制

ARP(地址解析协议), 把IP地址解析为MAC地址

解析MAC地址时，主机A首先在其ARP高速缓存中查找有无主机B的IP地址。

如果没有就就向**本地网段发起一个ARP请求的广播包**，查询此目的主机对应的MAC地址。网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果相同，该主机首先**将发送端的MAC地址和IP地址添加到自己的ARP列表中**，如果ARP表中已经存在该IP的信息，则将其覆盖，然后给源主机发送一个ARP响应数据包，**告诉对方自己是它需要查找的MAC地址**

#### HTTP协议

##### HTTP常见状态码

- 1xx: 请求处理中
- 2xx: 成功
- 3xx: 重定向
- 4xx: 客户端请求错误
- 5xx: 服务器错误

##### HTTP长连接和短连接

短连接：客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

长连接：客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。有一个保持时间

HTTP长连接是从HTTP1.1默认使用的

##### HTTP和HTTPS区别

1. HTTPS是在HTTP协议的基础上使用了TSL/SSl协议
2. HTTP协议默认端口80, HTTP协议默认端口443
3. HTTPS需要使用CA证书
4. HTTP明文传输, HTTPS使用对称和非对称加密

##### GET和POST区别

1. GET是从服务器获取数据(GET幂等), POST是提交数据
2. GET参数构建在URL种, POST构建在Body中
3. GET请求参数受限制(URL长度2048字节)
4. GET可被存为书签,历史记录中,POST参数不会被保存,相对安全
5. GET对参数要求为AscII字符,POST无限制

##### Cookie和Session区别

**Cookie** 和 **Session** 都是用来解决HTTP无状态限制的

1. Cookie 储存在客户端, Session 储存在服务端
2. 用户初次访问或登录等服务器会下发 Cookie 作为用户凭证
3. 用户访问服务器会携带 Cookie,作为凭证解决无状态限制

##### HTTP请求报文和响应格式

请求报文格式：

1. 请求行（请求方法+URI协议+版本）
2. 请求头部
3. 空行
4. 请求主体

```http
GET/sample.jspHTTP/1.1 请求行
Accept:image/gif.image/jpeg, 请求头部
Accept-Language:zh-cn
Connection:Keep-Alive
Host:localhost
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)
Accept-Encoding:gzip,deflate

username=jinqiao&password=1234 请求主体
```

响应报文：

1. 状态行（版本+状态码+原因短语）
2. 响应首部
3. 空行
4. 响应主体

```http
HTTP/1.1 200 OK
Server:Apache Tomcat/5.0.12
Date:Mon,6Oct2003 13:23:42 GMT
Content-Length:112

<html>
    <head>
        <title>HTTP响应示例<title>
    </head>
    <body>
        Hello HTTP!
    </body>
</html>
```

##### HTTP1.0和HTTP1.1和HTTP2.0区别

1. http1.0
   仅支持保持短暂的TCP链接
   不追踪ip

2. http1.1
   支持长连接
   纯文本报头
   增加了更多的请求头和响应头
   连接数过多 容易队首阻塞 且串行传输

3. http2.0
   多路复用，并行请求
   二进制报头 数据帧
   对报头压缩，降低开销
   服务器主动推送，减少请求延迟
   默认使用加密 增加伪头字段

#### IP地址

##### IP地址格式

什么是IP地址？IP协议提供的一种统一的地址格式，**它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。**

IP地址编址方案将IP地址空间划分为A、B、C、D、E五类，其中A、B、C是基本类，D、E类作为多播和保留使用，为特殊地址。

每个IP地址包括两个标识码（ID）

- 网络ID
- 主机ID。

同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。3字节的网络地址 + 1字节主机地址的意思就是：前三段号码为网络号码，剩下的一段号码为本地计算机的号码。

- **A类地址**：1字节的网络地址 + 3字节主机地址，网络地址的最高位必须是0。A类IP地址的地址范围1.0.0.0到127.255.255.255，IP地址的子网掩码为255.0.0.0，每个网络支持的最大主机数为`256^3-2`
- **B类地址**：2字节的网络地址 + 2字节主机地址，网络地址的最高位必须是10。B类IP地址地址范围128.0.0.0-191.255.255.255B类IP地址的子网掩码为255.255.0.0，每个网络支持的最大主机数为`256^2-2`。注：1000 0000=128
- **C类地址**：3字节的网络地址 + 1字节主机地址，网络地址的最高位必须是110。C类IP地址范围192.0.0.0-223.255.255.255每个网络支持的最大主机数为`256-2`。**适用于小规模局域网络**。
- **D类地址**：多播地址，用于1对多通信，最高位必须是1110。范围从224.0.0.0到239.255.255.255。
- **E类地址**:为保留地址，最高位必须是“1111”

##### 单播、广播和多播区别

**单播：主机间一对一通信**。优点：个性化服务，及时响应；缺点：流量压力大。

**广播：主机间一对所有通信**。优点：布局简单，维护方便，流量负载低。缺点：缺乏个性化服务，无法在Internet宽带上传播。

**多播（组播）：主机间一对一组通信**。优点：兼具流量负载和个性化的优点，允许在Internet宽带上传播。缺点：与单播协议相比没有纠错机制。

##### 如何进行子网划分

#### 安全

##### 什么是DDos攻击

DDos全称Distributed Denial of Service，分布式拒绝服务攻击。最基本的DOS攻击过程如下：

1. 客户端向服务端发送请求链接数据包
2. 服务端向客户端发送确认数据包
3. 客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认

DDoS则是采用分布式的方法，通过在网络上占领多台“肉鸡”，用多台计算机发起攻击。

DOS攻击现在基本没啥作用了，因为服务器的性能都很好，而且是多台服务器共同作用，1V1的模式黑客无法占上风。对于DDOS攻击，预防方法有：

- **减少SYN timeout时间。**在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源。
- **限制同时打开的SYN半连接数目。**

##### 什么是XSS攻击

XSS也称 cross-site scripting，**跨站脚本**。这种攻击是**由于服务器将攻击者存储的数据原原本本地显示给其他用户所致的**。比如一个存在XSS漏洞的论坛，用户发帖时就可以引入**带有＜script＞标签的代码**，导致恶意代码的执行

预防措施有：

- 前端：过滤
- 后端：转义，比如go自带的处理器就具有转义功能

##### 什么是SQL注入攻击

XSS是将脚本代码注入，而SQL注入攻击顾名思义就是注入SQL语句。

比如代码：

```go
username:=r.Form.Get("username")
password:=r.Form.Get("password")
sql:="SELECT * FROM user WHERE username='"+username+"' AND password='"+password+"'"
```

当用户输入`myuser' or 'foo' = 'foo' --`，那么SQL就变成了：

```go
SELECT * FROM user WHERE username='myuser' or 'foo'=='foo' --'' AND password='xxx'
```

在SQL里面`--`是注释标记，所以查询语句会在此中断。这就让攻击者在不知道任何合法用户名和密码的情况下成功登录了。

预防方法：

- 限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。
- 对进入数据库的特殊字符（’”\尖括号&*;等）转义处理。
- 提供参数化查询接口，不要直接使用原生SQL

#### 综合问题

##### 浏览器输入URL道显示页面的过程(HTTPS协议)

1. DNS解析
2. 客户端使用`https`协议访问服务器, 要求建立`ssl`连接
3. 服务器下发证书, `ssl`握手

##### ```ping```命令具体过程是什么

假设现在有ABCD四台主机，一台路由，子网掩码为255.255.255.0，默认路由为192.168.0.1

在主机 A 上运行`Ping 192.168.0.5`后,

1. Ping命令会构建一个**ICMP协议**的数据包，交到网络层的IP协议中。IP层协议将目的地址和源地址打包后，形成IP数据包
2. 获取192.168.0.5的MAC地址
3. 交到数据链路层，添加一些控制信息，构建数据帧
4. 交到物理层，通过以太网访问

主机B收到后，

1. 检查目的地址，不相符就丢弃
2. 将IP数据包提取后送入网络层的IP层协议，IP层检查后将有用的信息提取后送入ICMP协议
3. ICMP协议马上构建一个ICMP应答包以之前的相同方式发送给主机

##### 负载均衡算法

多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，能互相分担负载。

- 轮询法：将请求按照顺序轮流的分配到服务器上。大锅饭，不能发挥某些高性能服务器的优势
- 随机法：随机获取一台，和轮询类似
- 哈希法：通过ip地址哈希化来确定要选择的服务器编号。好处是,每次客户端访问的服务器都是同一个服务器，能很好地利用session或者cookie
- 加权轮询：根据服务器性能不同加权

##### Nginx 反向代理原理

#### 总体结构

![cn_sructure](https://user-gold-cdn.xitu.io/2018/7/29/164e529309f0fa33?imageslim)

### 数据库

#### 数据库基础

##### 事务的概念和特性

概念：事务（Transaction）是一个操作序列，不可分割的工作单位，以BEGIN TRANSACTION开始，以ROLLBACK/COMMIT结束

特性（ACID）：

- **原子性**（Atomicity）：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；
- **一致性**（Consistency）：事务的执行必须使数据库保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的；
- **隔离性**（Isolation）：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；
- **持久性**（Durability）：一旦事务提交成功，对数据的修改是永久性的

##### 会出现哪些事务并发一致性问题

- **丢失修改**：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改；
- **脏读**（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；
- **不可重复读**（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（可能被更新或删除了）；
- **幻读**（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了**插入操作**，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且需要是插入操作）

##### 数据库的四种隔离级别

- **未提交读**（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；
- **提交读**（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；
- **可重复读**（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（MySQL的默认隔离级别）。可避免不可重复读；
- **可串行化**（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。

##### 悲观锁和乐观锁

- 悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于**数据更新比较频繁**的场景；

- 乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于

  读多写少

  的场景。乐观锁的实现方式有：

  - 加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；
  - 先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新

##### 常见封锁类型

意向锁是 InnoDB 自动加的， 不需用户干预。 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB 会自动给涉及数据集加排他锁（X)； 对于普通 SELECT 语句，InnoDB 不会加任何锁； 事务可以通过以下语句显式给记录集加共享锁或排他锁： 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁

- **排它锁**（Exclusive Lock）/ X锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；

- **共享锁**（Shared Lock）/ S锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁

- 意向锁

  （Intention Locks）：

  - 一个事务在获得某个**数据行**对象的 S 锁之前，必须先获得**整个表**的 IS 锁或更强的锁；
  - 一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；
  - IS/IX 锁之间都是兼容的；
  - 好处：如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了

锁的作用：用于管理对共享资源的并发访问，保证数据库的完整性和一致性

##### 三级封锁协议

- 一级封锁协议：事务在修改数据之前必须先对其加X锁，直到事务结束才释放。可以解决丢失修改问题（两个事务不能同时对一个数据加X锁，避免了修改被覆盖）；
- 二级封锁协议：在一级的基础上，事务在读取数据之前必须先加S锁，读完后释放。可以解决脏读问题（如果已经有事务在修改数据，就意味着已经加了X锁，此时想要读取数据的事务并不能加S锁，也就无法进行读取，避免了读取脏数据）；
- 三级封锁协议：在二级的基础上，事务在读取数据之前必须先加S锁，直到事务结束才能释放。可以解决不可重复读问题（避免了在事务结束前其它事务对数据加X锁进行修改，保证了事务期间数据不会被其它事务更新）

##### MySQL封锁力度

MySQL 中提供了两种封锁粒度：**行级锁**以及**表级锁**。

封锁粒度小：

- 好处：锁定的数据量越少，发生锁争用的可能就越小，系统的**并发程度**就越高；
- 坏处：**系统开销**大（加锁、释放锁、检查锁的状态都需要消耗资源）

##### 两段锁协议

事务必须严格分为两个阶段对数据进行**加锁和解锁**的操作，第一阶段加锁，第二阶段解锁。也就是说一个事务中一旦释放了锁，就不能再申请新锁了。

**可串行化调度**是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。事务遵循两段锁协议是保证可串行化调度的充分条件。

##### 什么是 MVCC

多版本并发控制（Multi-Version Concurrency Control, MVCC），MVCC在每行记录后面都保存有两个隐藏的列，用来存储**创建版本号**和**删除版本号**。

- 创建版本号：创建一个数据行时的事务版本号（**事务版本号**：事务开始时的系统版本号；系统版本号：每开始一个新的事务，系统版本号就会自动递增）；
- 删除版本号：删除操作时的事务版本号；
- 各种操作：
  - 插入操作时，记录创建版本号；
  - 删除操作时，记录删除版本号；
  - 更新操作时，先记录删除版本号，再新增一行记录创建版本号；
  - 查询操作时，要符合以下条件才能被查询出来：删除版本号未定义或大于当前事务版本号（删除操作是在当前事务启动之后做的）；创建版本号小于或等于当前事务版本号（创建操作是事务完成或者在事务启动之前完成）

通过版本号减少了锁的争用，**提高了系统性能**；可以实现**提交读**和**可重复读**两种隔离级别，未提交读无需使用MVCC

##### 数据库范式

- **第一范式**（1NF，Normal Form）：**属性不应该是可分的**。
  举例：如果将“电话”作为一个属性（一列），是不符合1NF的，因为电话这个属性可以分解为家庭电话和移动电话...如果将“移动电话”作为一个属性，就符合1NF；

- 第二范式

  2NF：**每个非主属性完全依赖于主属性集（候选键集）**

  - B完全依赖于A，就是说A中的所有属性唯一决定B，属性少了就不能唯一决定，属性多了则有冗余（叫依赖不叫完全依赖）。举例：（学号，课程名）这个主属性集可以唯一决定成绩，但是对于学生姓名这个属性，（学号，课程名）这个属性集就是冗余的，所以学生姓名不完全依赖于（学号，课程名）这一属性集；
- 主属性集/候选码集：某一组属性能够唯一确定其它的属性（主键就是从候选键集中选的一个键），而其子集不能，这样的属性组中的属性就是主属性；不在候选码集中的属性成为非主属性；
  
- 可以通过分解来满足 2NF：将（学号，课程名，成绩）做成一张表；（学号，学生姓名）做成另一张表，避免大量的数据冗余； 满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；
  
- 第三范式

  3NF：**在 2NF 的基础上，非主属性不传递依赖于主属性**

  - 传递依赖：如果C依赖于B，B依赖于A，那么C传递依赖于A；
- 3NF在2NF的基础上，消除了非主属性之间的依赖；比如一个表中，主属性有（学号），非主属性有（姓名，院系，院长名），可以看到院长名这个非主属性依赖于院系，传递依赖于学号。消除的办法是分解。 必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；

##### 查询连接方式

- 内连接（Inner Join）：仅将两个表中满足连接条件的行组合起来作为结果集
  - 自然连接：只考虑属性相同的元组对；
  - 等值连接：给定条件进行查询
- 外连接（Outer Join）
  - 左连接：左边表的所有数据都有显示出来，右边的表数据只显示共同有的那部分，没有对应的部分补NULL；
  - 右连接：和左连接相反；
  - 全外连接（Full Outer Join）：查询出左表和右表所有数据，但是去除两表的重复数据
- 交叉连接（Cross Join）：返回两表的笛卡尔积（对于所含数据分别为m、n的表，返回m*n的结果）

##### 储存过程及优缺点

存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。想要实现相应的功能时，只需要调用这个存储过程就行了（类似于函数，输入具有输出参数）。

优点：

- 预先编译，而不需要每次运行时编译，提高了数据库执行**效率**；
- 封装了一系列操作，对于一些数据交互比较多的操作，相比于单独执行SQL语句，可以**减少网络通信量**；
- 具有**可复用性**，减少了数据库开发的工作量；
- **安全性高**，可以让没有权限的用户通过存储过程间接操作数据库；
- 更**易于维护**

缺点：

- **可移植性差**，存储过程将应用程序绑定到了数据库上；
- **开发调试复杂**：没有好的IDE；
- **修改复杂**，需要重新编译，有时还需要更新程序中的代码以更新调用

##### Drop/Delete/Truncate

- **Delete**用来删除表的全部或者**部分数据**，执行delete之后，用户**需要提交**之后才会执行，会触发表上的DELETE**触发器**（包含一个OLD的虚拟表，可以只读访问被删除的数据），DELETE之后表结构还在，删除很慢，一行一行地删，因为会记录日志，可以利用日志还原数据；
- **Truncate**删除表中的所有数据，这个操作**不能回滚**，也不会触发这个表上的触发器。操作比DELETE快很多（直接把表drop掉，再创建一个新表，删除的数据不能找回）。如果表中有自增（AUTO_INCREMENT）列，则重置为1；
- **Drop**命令从数据库中**删除表**，所有的数据行，索引和约束都会被删除；不能回滚，不会触发触发器；

##### 什么是视图?什么是游标

- 视图：从数据库的基本表中通过查询选取出来的数据组成的虚拟表（数据库中存放视图的定义）。可以对其进行增/删/改/查等操作。视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查操作(ps:增删改操作有条件限制)；如连表查询产生的视图无法进行，对视图的增删改会影响原表的数据。好处：

  - 通过只给用户访问视图的权限，保证数据的**安全性**；
- **简化**复杂的SQL操作，隐藏数据的复杂性（比如复杂的连接）；
  
- 游标（Cursor）：用于定位在查询返回的**结果集的特定行**，以对特定行进行操作。使用游标可以方便地对结果集进行移动遍历，根据需要滚动或对浏览/修改任意行中的数据。主要用于交互式应用。

##### SQL约束有哪几种

NOT NULL: 用于控制字段的内容一定不能为空（NULL）

UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束 `UNIQUE (Id_P)`

PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个 `PRIMARY KEY (Id_P)`

FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一
`FOREIGN KEY (Id_P) REFERENCES Persons(Id_P)`

CHECK: 用于控制字段的值范围 `CHECK (Id_P>0)`

#### MySQL

##### 分库分表

- **水平切分**
  - range
    0-10000在一个表, 100001-200000在一个表
  - 按照地区分
  - 按照时间分
- **垂直切分**
  - 垂直分库
  - 垂直分表
    也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题

##### 查看是否使用索引

语句前加上`explain`

##### 数据库索引实现原理

**使用B树和B+树的比较**

InnoDB的索引使用的是B+树实现，B+树对比B树的好处：

- IO次数少：B+树的中间结点只存放索引，数据都存在叶结点中，因此中间结点可以存更多的数据，让索引树更加矮胖；
- 范围查询效率更高：B树需要中序遍历整个树，只B+树需要遍历叶结点中的链表；
- 查询效率更加稳定：每次查询都需要从根结点到叶结点，路径长度相同，所以每次查询的效率都差不多

**使用B树索引和哈希索引的比较**

哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，无法用于部分查找和范围查找，无法用于排序与分组；B树索引支持大于小于等于查找，范围查找。哈希索引遇到大量哈希值相等的情况后查找效率会降低。哈希索引不支持数据的排序。

##### 使用索引的优点

- 大大加快了数据的**检索速度**；
- 可以显著减少查询中**分组和排序**的时间；
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；
- 将随机 I/O 变为**顺序 I/O**（B+Tree 索引是有序的，会将相邻的数据都存储在一起）

缺点：建立和维护索引耗费时间空间，更新索引很慢。

##### 哪些情况下索引会失效

- 以“%(表示任意0个或多个字符)”开头的LIKE语句；
- OR语句前后没有同时使用索引；
- 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；
- 对于多列索引，必须满足 **最左匹配原则**/最左前缀原则 (最左优先，eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)；
- 如果MySQL估计全表扫描比索引快，则不使用索引（比如非常小的表）

#####  哪些地方适合建立索引

- 某列经常作为最大最小值；
- 经常被查询的字段；
- 经常用作表连接的字段；
- 经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段

##### 索引的分类

- 普通索引
- 唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；
- 主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引）；
- 单列索引和多列索引/复合索引（Composite）：索引的列数；
- 覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；
- 聚集（Clustered）索引/非聚集索引：对磁盘上存放数据的物理地址重新组织以使这些数据按照指定规则排序的一种索引（数据的物理排列顺序和索引排列顺序一致）。因此每张表只能创建一个聚集索引（因为要改变物理存储顺序）。优点是查询速度快，因为可以直接按照顺序得到需要数据的物理地址。缺点是进行修改的速度较慢。对于需要经常搜索范围的值很有效。非聚集索引只记录逻辑顺序，并不改变物理顺序；
- 分区索引（？）
- 虚拟索引（Virtual）：模拟索引的存在而不用真正创建一个索引，用于快速测试创建索引对执行计划的影响。没有相关的索引段，不增加存储空间的使用

##### MySQL的两种(常考,不止两种)储存引擎

- InnoDB**支持事务**，可以进行Commit和Rollback；
- MyISAM 只支持表级锁，而 InnoDB 还**支持行级锁**，提高了并发操作的性能；
- InnoDB **支持外键**；
- MyISAM **崩溃**后发生损坏的概率比 InnoDB 高很多，而且**恢复的速度**也更慢；
- MyISAM 支持**压缩**表和空间数据索引，InnoDB需要更多的内存和存储；
- InnoDB 支持在线**热备份**

##### 如何优化数据库

##### 主从复制,实现原理

主从复制（Replication）是指数据可以从一个MySQL数据库主服务器复制到一个或多个从服务器，从服务器可以复制主服务器中的所有数据库或者特定的数据库，或者特定的表。默认采用异步模式。

实现原理：

- 主服务器 **binary log dump 线程**：将主服务器中的数据更改（增删改）日志写入 Binary log 中；
- 从服务器 **I/O 线程**：负责从主服务器读取binary log，并写入本地的 Relay log；
- 从服务器 **SQL 线程**：负责读取 Relay log，解析出主服务器已经执行的数据更改，并在从服务器中重新执行（Replay），保证主从数据的一致性

##### 数据表损坏的修复方式

使用 myisamchk 来修复，具体步骤：

- 1）修复前将mysql服务停止。
- 2）打开命令行方式，然后进入到mysql的/bin目录。
- 3）执行myisamchk –recover 数据库所在路径/*.MYI

使用repair table 或者 OPTIMIZE table命令来修复，REPAIR TABLE table_name 修复表 OPTIMIZE TABLE table_name 优化表 REPAIR TABLE 用于修复被破坏的表。 OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了OPTIMIZE TABLE命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库）

##### MySQL默认文件

##### 那种模式运行可保证数据不丢失

**在archivelog mode(归档模式)只要其归档日志文件不丢失，就可以有效地防止数据丢失。**

##### MySQL语句(TODO)

#### NoSQL/Redis

##### 关系型数据库和非关系型数据库区别

##### Redis数据类型

Redis主要有5种数据类型，包括

- String
  - set key value
  - get key
- List
- Set
  - sadd
- Zset
  - zadd
- Hash
  - hmset
  - hdel
  - hexists
  - hget

##### Redis 性能

1. **完全基于内存**，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)

2. **数据结构简单**，对数据操作也简单，Redis 中的数据结构是专门进行设计的

3. **采用单线程**，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗

4. **使用多路 I/O 复用模型，非阻塞 IO**

5. **使用底层模型不同**，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求

##### 如何保障热点数据

redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）。redis 提供 6种数据淘汰策略：

1. **volatile-lru**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru**：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-enviction**（驱逐）：禁止驱逐数据

##### Redis线程模型

Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。

文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性

##### Redis 两种数据持久化方式

[Redis](http://redis.io/)有两种持久化的方式：快照（`RDB`文件）和追加式文件（`AOF`文件）：

- RDB持久化方式会在一个特定的间隔保存那个时间点的一个数据快照。
- AOF持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。
- Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。
- 两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被优先用于重建数据。

**RDB**

**工作原理**

- Redis调用fork()，产生一个子进程。
- 子进程把数据写到一个临时的RDB文件。
- 当子进程写完新的RDB文件后，把旧的RDB文件替换掉。

**优点**

- RDB文件是一个很简洁的单文件，它保存了某个时间点的Redis数据，很适合用于做备份。你可以设定一个时间点对RDB文件进行归档，这样就能在需要的时候很轻易的把数据恢复到不同的版本。
- 基于上面所描述的特性，RDB很适合用于灾备。单文件很方便就能传输到远程的服务器上。
- RDB的性能很好，需要进行持久化时，主进程会fork一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的I/O操作。
- 比起AOF，在数据量比较大的情况下，RDB的启动速度更快。

**缺点**

- RDB容易造成数据的丢失。假设每5分钟保存一次快照，如果Redis因为某些原因不能正常工作，那么从上次产生快照到Redis出现问题这段时间的数据就会丢失了。
- RDB使用`fork()`产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成Redis停止服务几毫秒。如果数据量很大且CPU性能不是很好的时候，停止服务的时间甚至会到1秒。

**AOF**

快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。

**优点**

- 比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。
- AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用`redis-check-aof`这个工具很简单的进行修复。
- 当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。
- AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用`FLUSHALL`命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。

**缺点**

- 在相同的数据集下，AOF文件的大小一般会比RDB文件大。
- 在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。
- 在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。

##### Redis 如何防止数据出错

##### Redis 如何使用流水线提高性能

##### Redis 主从复制

单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发

![](https://img-blog.csdnimg.cn/20200115180329317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua3dvbi5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

##### Redis 集群搭建

##### Redis 几种淘汰策略

- **定时过期**
  每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
- **惰性过期**
  只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
- **定期过期**
  每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
  (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

##### Redis 集群宕机, 数据迁移问题

##### Redis 缓存穿透, 缓存雪崩, 缓存击穿, 缓存预热, 缓存降级, 热点数据和冷数据, 缓存热点Key

- **缓存穿透**
  缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

  **解决方案**

  1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
  2. 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
  3. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

- **缓存雪崩**
  缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

  **解决方案**

  1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生
  2. 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队
  3. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存

- **缓存击穿**
  缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

  **解决方案**

  1. 设置热点数据永远不过期。
  2. 加互斥锁，互斥锁

- **缓存预热**
  缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

  **解决方案**

  1. 直接写个缓存刷新页面，上线时手工操作一下
  2. 数据量不大，可以在项目启动的时候自动进行加载
  3. 定时刷新缓存

- **缓存降级**
  当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

  缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

  在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别**设置预案**：

  1. 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
  2. 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
  3. 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
  4. 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

  **服务降级的目的**: 防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。

- **热点数据和冷数据**
  热点数据，缓存才有价值

  对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存

  对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。

  数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。

  那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。

- **缓存热点Key**
  缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

  解决方案

  对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询

##### 缓存数据库双写一致问题

先淘汰缓存，再写数据库

####  附录

##### SQL相关

![SQL](https://user-gold-cdn.xitu.io/2018/3/5/161f3dcd8a20045c?imageslim)

##### SQL知识

![](https://user-gold-cdn.xitu.io/2018/3/5/161f3dd44e3b3d59?imageslim)



### 操作系统

#### 进程和线程

##### 进程和线程有什么区别

- 进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位；
- 线程依赖于进程而存在，一个进程至少有一个线程；
- 进程有自己的独立地址空间，线程共享所属进程的地址空间；
- 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；
- 在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；
- 线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；
- 多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮

##### 同一进程中的线程可以共享那些数据

- 进程代码段
- 进程的公有数据（全局变量、静态变量...）
- 进程打开的文件描述符
- 进程的当前目录
- 信号处理器/信号处理函数：对收到的信号的处理方式
- 进程ID与进程组ID

##### 线程独占哪些资源

- 线程ID
- 一组寄存器的值
- 线程自身的栈（堆是共享的）
- 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；
- 信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）

##### Python 中调用fork()

```Python
import os

print('Process (%s) start...' % os.getpid())
# Only works on Unix/Linux/Mac:
# 子进程返回 0
pid = os.fork()
if pid == 0:
    print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))
else:
    print('I (%s) just created a child process (%s).' % (os.getpid(), pid))
```

##### 进程间通信方式

- **管道**（pipe）及**命名管道**（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信
- **信号**（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
- **消息队列**：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息
- **共享内存**：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等
- **信号量**：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段
- **套接字**：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛

#### 线程同步的方式

- **互斥量**(Synchronized/Lock)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
- **信号量**(Semphare)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
- **事件/信号**(Wait/Notify)：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

##### 什么是僵尸进程

一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。

危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。

以下情况不会产生僵尸进程：

- 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。
- 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入`WNOHANG`(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程；
- 子进程结束时，系统会产生`SIGCHLD`(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）；
- 也可以用`signal(SIGCLD, SIG_IGN)`(signal-ignore)通知内核，表示忽略`SIGCHLD`信号，那么子进程结束后，内核会进行回收

##### 什么是孤儿进程

一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。

##### 什么是 I/O 多路复用

O多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。

实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。

##### select/poll/epoll 区别

- `select`：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，**开销大**），由内核根据就绪状态修改该集合的内容。（缺点2）**集合大小有限制**，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：**轮询的方式效率较低**），当文件描述符的数量增加时，效率会线性下降；
- `poll`：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；
- `epoll`：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。

总结，区别主要在于：

- 一个线程/进程所能打开的最大连接数
- 文件描述符传递方式（是否复制）
- 水平触发 or 边缘触发
- 查询就绪的描述符时的效率（是否轮询）

##### 什么时候用select/poll, 什么时候用 epoll

当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。

##### 常见 I/O模型

- 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；
- 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；
- IO多路复用
  - 
- 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。
- 信号驱动IO

##### 什么是用户态和内核态

为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。

- 用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；
- 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。

所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用**陷阱指令**，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。

##### 为什么要区分用户态和内核态

- 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；
- 封装性：用户程序不需要实现更加底层的代码；
- 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。

##### 如何从用户态切换到内核态

- 系统调用：比如读取命令行输入。本质上还是通过中断实现
- 用户程序发生异常时：比如缺页异常
- 外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序

#### 死锁

##### 什么是死锁

在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。

##### 死锁产生的必要条件

- **互斥**：一个资源一次只能被一个进程使用；
- **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；
- **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；
- **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。

##### 死锁有哪些处理方法？

- 鸵鸟策略
  直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

- 死锁预防
  基本思想是破坏形成死锁的四个必要条件：

  - 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；
  - 破坏占有并等待条件：
    - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；
    - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；
    - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；
  - 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；
  - 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。

- 死锁避免
  动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。

- 死锁解除
  如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。

  死锁解除的方法：

  - 利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；
  - 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；
  - 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。

#### 内存管理

##### 分页和分段有什么区别

- 页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；
- 段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；
- 段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。

区别：

- 目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；
- 大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；
- 地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；
- 分段便于信息的保护和共享；分页的共享收到限制；
- 碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）

##### 什么是虚拟内存

每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。

虚拟内存的优点是让程序可以获得更多的可用内存。

##### 如何进行地址空间到物理内存的映射

**内存管理单元**（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。

##### 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

- **最佳页面置换算法**OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；
- **先进先出**FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；
- **第二次机会算法**SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；
- **时钟算法** Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；
- **最近未使用算法**NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；
- **最近最少使用算法**LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
- **最不经常使用算法**NFU：置换出访问次数最少的页面

##### 磁盘调度

过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：

- 先来先服务
- 最短寻道时间优先
- 电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

#### 算法(TODO)

##### Python 实现线程和进程

##### 银行家算法

##### 生产者消费者问题

##### LRU算法

##### 电梯算法

### Python

#### 基础

##### 什么是 Python 生成器

`yield`相当于`return`,下次会从`yeild`后继续执行函数

##### 什么是 Python 迭代器

迭代器可以被`next`调用,返回下一个值

##### List 和 Tuple 的区别

1. `list`长度可变, `tuple`长度不可变
2. `list`值可变, `tuple`值不可变
3. `list`支持`append`、`pop`、`insert`等方法,`tuple`不支持

##### Python 中List 和 Dict怎么实现的

`list`指针数组, `dict`哈希表, 开放寻址法处理冲突

##### Python 中多线程可以达到多核CPU一起使用吗

不能, Python `GIL`

- 为什么会有`GIL`
  - `GIL`实际上是`CPython`的问题, 根据官方[`wiki`](https://wiki.python.org/moin/GlobalInterpreterLock)解释`CPython`内存管理不是吧线程安全的,因此需要`GIL`来保证线程安全
  - 单线程情况下更快
  - 瓶颈在于 I/O 的多线程环境下更快
- 含`GIL`的解释器: `CPython`、`PyPy`...
- 不含`GIL`的解释器: `JPython`

##### 什么是装饰器

本质上是一个函数

```python
def use_logging(func):

    def wrapper(*args, **kwargs):
        logging.warn("%s is running" % func.__name__)
        return func(*args)
    return wrapper

def use_logging(text)
	def decorator(func)
    	def wrapper(*args, **kwargs):
            logging.info("this is a demo text is {}".format(text))
            return func(*args, **kwargs)
     return wrapper
return decorator
```

##### Python 中的GC

- 引用计数

  ```c
   typedef struct_object {
   int ob_refcnt; //ob_refcnt 计数器
   struct_typeobject *ob_type;
  } PyObject;
  
  #define Py_INCREF(op)   ((op)->ob_refcnt++) //增加计数
  #define Py_DECREF(op) \ //减少计数
      if (--(op)->ob_refcnt != 0) \
          ; \
      else \
          __Py_Dealloc((PyObject *)(op))
  ```

  

  引用一次`ob_refcnt`加 1, 对象被删除`ob_refcnt` 减 1, 当`ob_refcnt` 为 0 时, 对象生命周期结束

  - 标记清除
    两个链表`root`和`unreachable`, 同时会有一个`ob_refcnt`的副本`gc_ref`
    扫描时会将被引用对象的`gc_ref` - 1
    将`gc_ref` 为 0 的对象放入`unreachable`中, 标记为`gc_unreachable`
    当`GC`发现有一个节点是可达的, 会以递归的形式将该节点可达节点标记为`gc_reachable`, 并且放入`root`链表

- 分代回收
  对象存在时间越长，越可能不是垃圾，应该越少去收集
  分了三代(0, 1, 2), 当 0 代扫描**指定**的次数后, 1 代会启动一次扫描
  当 1 代启动扫描后, 0代必定启动扫描
  当对象或过一次扫描, 那么就将其放入下一代, 接受更少的扫描

##### lambda 表达式

简单来说，lambda表达式通常是当你需要使用一个函数，但是又不想费脑袋去命名一个函数的时候使用，也就是通常所说的匿名函数。

lambda表达式一般的形式是：关键词lambda后面紧接一个或多个参数，紧接一个冒号“：”，紧接一个表达式

```python
g = lambda x, y, z : (x + y) ** z
print g(1,2,2)
```

##### 深拷贝和浅拷贝

赋值（=），就是创建了对象的一个新的引用，修改其中任意一个变量都会影响到另一个。

浅拷贝 copy.copy：创建一个新的对象，但它包含的是对原始对象中包含项的引用（如果用引用的方式修改其中一个对象，另外一个也会修改改变）

深拷贝：创建一个新的对象，并且递归的复制它所包含的对象（修改其中一个，另外一个不会改变）{copy模块的deep.deepcopy()函数}

##### is 和 == 的区别

`is` 判断对象`id`是否相等

`==`判断值是否相等

`Python`中对小数据有缓存机制，-5~256之间的数据都会被缓存

#### 其他Python知识

##### 类型装换

### 分布式

### Linux常用命令(TODO)

##### ls

- `ls -a` 列出目录所有文件，包含以.开始的隐藏文件
- `ls -A` 列出除.及..的其它文件
- `ls -r` 反序排列
- `ls -t` 以文件修改时间排序
- `ls -S` 以文件大小排序
- `ls -h` 以易读大小显示
- `ls -l` 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来

##### cd

##### pwd

##### mkdir

- `mkdir -p`在某个目录下创建,如果目录不存在则创建

##### rm (慎用)

##### rmdir (慎用)

##### mv

##### cp

##### cat

##### more

##### less

##### head

##### tial

##### which

##### whereis

##### loacte

##### find

##### chmod

##### tar

##### chwon

#####  df

##### du

##### ln

##### date

##### cal

##### grep

##### wc

##### ps

##### top

##### kill

##### free

### 正则表达式

### Git

#### 新建代码库

##### 在当前目录建立 Git 代码库

```git init```

###### 新建一个文件夹,并且初始化为 Git 代码库

```git init [project name]```

###### 下载一个项目和整个代码历史

```git clone [url]```

###### 配置

**Git** 配置文件为.gitconfig, 可以再全局配置, 也可在项目目录下配置

##### 显示当前 Git 配置

```git config --list```

##### 编辑 Git 配置文件

```git config -e  [--golbal]	```

##### 设置提交代码时的用户信息

```git config [--global] user.name '[name]'```

```git config [--global] user.emial '[emial]'```

#### 增加/删除文件

##### 添加指定文件道暂存区

```git add [file1] [file2] ...```

##### 添加指定目录到暂存区(包括子目录)

```git add [dir]```

##### 添加所有文件到暂存区

```git add *```

##### 添加每个变化前, 都会要求确认, 对于同一个文件的多处变化, 可以实现分次提交

```git add -p```

##### 删除工作区文件, 并且将这次删除放入暂存区

```git rm [file1] [file2] ...```

##### 停止追踪指定文件

```git rm --cached [file]```

##### 改名文件, 并将此次改名放入暂存区

```git mv [file-original] [file-renamed]```

#### 代码提交

##### 提交暂存区到仓库区

```git commit -m [message]```

##### 提交暂存区的指定文件到仓库区

```git commit [file1] [file2] ... -m [msssage]```

##### 提交工具区自上次提交后的变化, 直接到仓库区

```git commit -a```

##### 提交时显示所有 diff 信息

```git commit -v```

##### 使用一次新的提交, 替换上一次的提交, 如果代码没有变化, 则用来改写上次的提交信息

```git commit -amend -m [message]```

##### 重做上一次提交, 并且指定文件的新变化

`git commit -amend [file1] [file2] ...`

#### 分支

##### 列出所有分支

`git branch`

##### 	列出所有远程分支

`git branch -r`

##### 列出所有本地分支和远程分支

`git branch -a`

##### 新建一个分支, 停留在当前分支

`git branch [branch-name]`

##### 新建一个分支, 切换到新建分支

`git checkout -b [branch-name]`

##### 新建一个分支, 并指向 commit

`git branch [branch-name] [commit]`

##### 新建一个分支, 与指定远程分支建立追踪关系

`git branck --track [branch] [remote-branch]`

#####  切换到指定分支, 并更新工作区

`git checkout [branch-name]`

##### 切换到上一个分支

`git checkout -`

##### 建立追踪关系，在现有分支与指定的远程分支之间

`git branch --set-upstream [branch] [remote-branch]`

##### 合并指定分支到当前分支

`git merge [branch]`

##### 选择一个commit，合并进当前分支

`git cherry-pick [commit]`

##### 删除分支

`git branch -d [branch-name]`

##### 删除远程分支

`git push origin --delete [branch-name]`

`git branch -dr [remote/branch]`

#### 标签

##### 列出所有tag

`git tag`

##### 新建一个tag在当前commit

`git tag [tag]`

##### 新建一个tag在指定commit

##### `git tag [tag] [commit]`	

##### 删除本地tag

`git tag -d [tag]`

##### 删除远程tag

`git push origin :refs/tags/[tagName]`

##### 查看tag信息

`git show [tag]`

##### 提交指定tag

`git push [remote] [tag]`

##### 提交所有tag

`git push [remote] --tags`

##### 新建一个分支，指向某个tag

`git checkout -b [branch] [tag]`

#### 查看信息

##### 显示有变更的文件

`git status`

##### 显示当前分支的版本历史

`git log`

##### 显示commit历史，以及每次commit发生变更的文件

`git log --stat`

##### 搜索提交历史，根据关键词

`git log -S [keyword]`

##### 显示某个commit之后的所有变动，每个commit占据一行

`git log [tag] HEAD --pretty=format:%s`

##### 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件

`git log [tag] HEAD --grep feature`

##### 显示某个文件的版本历史，包括文件改名

`git log --follow [file]
`

`git whatchanged [file]`

##### 显示指定文件相关的每一次diff

`git log -p [file]`

##### 显示过去5次提交

`git log -5 --pretty --oneline`

##### 显示所有提交过的用户，按提交次数排序

`git shortlog -sn`

##### 显示指定文件是什么人在什么时间修改过

`git blame [file]`

##### 显示暂存区和工作区的差异

`git diff`

##### 显示暂存区和上一个commit的差异

`git diff --cached [file]`

##### 显示工作区与当前分支最新commit之间的差异

`git diff HEAD`

##### 显示两次提交之间的差异

`git diff [first-branch]...[second-branch]`

##### 显示今天你写了多少行代码

`git diff --shortstat "@{0 day ago}"`

##### 显示某次提交的元数据和内容变化

`git show [commit]`

##### 显示某次提交发生变化的文件

`git show --name-only [commit]`

##### 显示某次提交时，某个文件的内容

`git show [commit]:[filename]`

##### 显示当前分支的最近几次提交

`git reflog`

#### 远程同步

##### 下载远程仓库的所有变动

`git fetch [remote]`

##### 显示所有远程仓库

`git remote -v`

##### 显示某个远程仓库的信息

`git remote show [remote]`

##### 增加一个新的远程仓库，并命名

`git remote add [shortname] [url]`

##### 取回远程仓库的变化，并与本地分支合并

`git pull [remote] [branch]`

##### 上传本地指定分支到远程仓库

`git push [remote] [branch]`

##### 强行推送当前分支到远程仓库，即使有冲突

`git push [remote] --force`

##### 推送所有分支到远程仓库

`git push [remote] --all`

#### 撤销

##### 恢复暂存区的指定文件到工作区

`git checkout [file]`

##### 恢复某个commit的指定文件到暂存区和工作区

`git checkout [commit] [file]`

##### 恢复暂存区的所有文件到工作区

`git checkout .`

##### 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变

`git reset [file]`

##### 重置暂存区与工作区，与上一次commit保持一致

`git reset --hard`

##### 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致

`git reset --hard [commit]`

##### 重置当前HEAD为指定commit，但保持暂存区和工作区不变

`git reset --keep [commit]`

##### 新建一个commit，用来撤销指定commit

##### 后者的所有变化都将被前者抵消，并且应用到当前分支

`git revert [commit]`

##### 暂时将未提交的变化移除，稍后再移入

`git stash
`

`git stash pop`

#### 其他

##### 生成一个可供发布的压缩包

`git archive`

### END